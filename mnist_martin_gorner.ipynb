{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "* Dataset used - MNIST (with one-hot-encoding)\n",
    "* LOG_DIR = \"tmp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "LOG_DIR = \"tmp/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and Ground-truth placeholders  \n",
    "* One image is a 784 length vector with 0's and 1's  \n",
    "* Ground-truth is a label from 0-9  \n",
    ".  \n",
    "* Y  = ground-truth  \n",
    "* Y-underscore = predicted-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input 28-by-28 pixels images of GRAYSCALE\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# Output in 'one-hot-encoding', 10 classes\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "* **Input-layer**[784 neurons] >> (W, b) >> **Output-layer**[10 neurons]\n",
    "* **softmax** activation function used at output layer  \n",
    "\n",
    "### Dimensions\n",
    "* W[784, 10]  \n",
    "* b[10]  \n",
    " \n",
    "### Cost function  \n",
    "* cost = L1 norm \n",
    "  \n",
    "### Accuracy function  \n",
    "* Accuracy = (correct)/(correct + incorrect) %  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "W = tf.Variable(tf.truncated_normal([784, 10], stddev=0.75))\n",
    "tf.summary.histogram(\"weights\", W)\n",
    "b = tf.Variable(tf.truncated_normal([10], stddev=0.5))\n",
    "tf.summary.histogram(\"biases\", b)\n",
    "# model-output\n",
    "Y = (tf.matmul(X, W) + b)\n",
    "\n",
    "# variable-initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# cost\n",
    "cross_entropy = tf.reduce_sum(tf.abs(Y - Y_))\n",
    "tf.summary.scalar(\"cross_entropy\", cross_entropy)\n",
    "\n",
    "# accuracy\n",
    "is_correct = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and train_step\n",
    "* learning_rate\n",
    "* number_of_epochs\n",
    "* batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.003\n",
    "n_epochs = 1000\n",
    "batch_size = 100\n",
    "\n",
    "tf.summary.scalar(\"learning_rate\", learning_rate)\n",
    "tf.summary.scalar(\"number_of_epochs\", n_epochs)\n",
    "tf.summary.scalar(\"mini_batch_size\", batch_size)\n",
    "\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "* Mini-batch method used\n",
    "* train & test results stored separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "summaries = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(LOG_DIR + \"train\", graph=tf.get_default_graph())\n",
    "test_writer = tf.summary.FileWriter(LOG_DIR + \"test\", graph=tf.get_default_graph())\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    # feed train-data\n",
    "    batch_X, batch_Y = mnist.train.next_batch(batch_size)\n",
    "    train_data = {X: batch_X, Y_: batch_Y}\n",
    "    \n",
    "    summ, _ = sess.run([summaries, train_step], feed_dict=train_data)\n",
    "    train_writer.add_summary(summ, global_step=i)\n",
    "    \n",
    "    # feed test-data\n",
    "    test_data = {X: mnist.test.images, Y_: mnist.test.labels}\n",
    "    \n",
    "    summ = sess.run(summaries, feed_dict=test_data)\n",
    "    test_writer.add_summary(summ, global_step=i)\n",
    "    \n",
    "    # print\n",
    "    if i%4 == 0:\n",
    "        print (\"Iteration: \", i, \" complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
